<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Echo AI Chat</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 40px;
            max-width: 600px;
            width: 100%;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }

        h1 {
            color: #667eea;
            margin-bottom: 10px;
            font-size: 2em;
        }

        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 0.9em;
        }

        .config-section {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .config-row {
            display: flex;
            gap: 15px;
            margin-bottom: 15px;
            flex-wrap: wrap;
        }

        .config-group {
            flex: 1;
            min-width: 200px;
        }

        label {
            display: block;
            margin-bottom: 5px;
            color: #333;
            font-weight: 500;
            font-size: 0.9em;
        }

        input, select, textarea {
            width: 100%;
            padding: 10px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 14px;
            transition: border-color 0.3s;
            font-family: inherit;
        }

        textarea {
            resize: vertical;
            min-height: 60px;
        }

        input:focus, select:focus, textarea:focus {
            outline: none;
            border-color: #667eea;
        }

        .status {
            display: flex;
            align-items: center;
            gap: 10px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .status-indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #ccc;
            transition: background 0.3s;
        }

        .status-indicator.listening {
            background: #4caf50;
            animation: pulse 1.5s infinite;
        }

        .status-indicator.processing {
            background: #ff9800;
        }

        .status-indicator.speaking {
            background: #2196f3;
            animation: pulse 1s infinite;
        }

        .status-indicator.paused {
            background: #9e9e9e;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .status-text {
            color: #666;
            font-size: 0.9em;
        }

        .controls {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
        }

        button {
            flex: 1;
            padding: 15px 30px;
            border: none;
            border-radius: 10px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }

        .btn-primary {
            background: #667eea;
            color: white;
        }

        .btn-primary:hover {
            background: #5568d3;
            transform: translateY(-2px);
        }

        .btn-primary:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }

        .btn-secondary {
            background: #e0e0e0;
            color: #333;
        }

        .btn-secondary:hover {
            background: #d0d0d0;
        }

        .transcript-area {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            max-height: 300px;
            overflow-y: auto;
            margin-bottom: 20px;
        }

        .message {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 8px;
        }

        .message.user {
            background: #e3f2fd;
        }

        .message.ai {
            background: #f3e5f5;
        }

        .message.echo {
            background: #e8f5e9;
        }

        .message.system {
            background: #ffebee;
            font-size: 0.85em;
        }

        .message strong {
            display: block;
            margin-bottom: 5px;
            font-size: 0.85em;
            opacity: 0.7;
        }

        .help-text {
            font-size: 0.85em;
            color: #666;
            margin-top: 20px;
            padding: 15px;
            background: #fff3cd;
            border-radius: 8px;
            border-left: 4px solid #ffc107;
        }

        .info-text {
            font-size: 0.85em;
            color: #666;
            margin-top: 10px;
            padding: 12px;
            background: #e3f2fd;
            border-radius: 8px;
            border-left: 4px solid #2196f3;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸ¤– Echo AI Chat</h1>
        <p class="subtitle">Voice conversation between AI and your Echo device</p>

        <div class="config-section">
            <div class="config-row">
                <div class="config-group">
                    <label>Response Mode</label>
                    <select id="responseMode">
                        <option value="continuous">Continuous - Respond to all speech</option>
                        <option value="wakeword">Wake Word - Only respond to wake word</option>
                    </select>
                </div>
                <div class="config-group" id="wakeWordGroup">
                    <label>AI Wake Word</label>
                    <select id="aiWakeWord">
                        <option value="alexa">Alexa</option>
                        <option value="echo">Echo</option>
                        <option value="computer">Computer</option>
                        <option value="hey google">Hey Google</option>
                    </select>
                </div>
            </div>
            <div class="config-row">
                <div class="config-group">
                    <label>AI Model</label>
                    <select id="aiModel">
                        <option value="openai">OpenAI GPT-5 Mini</option>
                        <option value="gemini">Gemini 2.5 Flash</option>
                        <option value="deepseek">DeepSeek V3.1</option>
                        <option value="mistral">Mistral Small</option>
                    </select>
                </div>
            </div>
            <div class="config-row">
                <div class="config-group">
                    <label>Silence Threshold (ms)</label>
                    <input type="number" id="silenceThreshold" value="3000" min="1000" max="8000" step="500">
                </div>
                <div class="config-group">
                    <label>Post-Speech Pause (ms)</label>
                    <input type="number" id="postSpeechPause" value="3000" min="1000" max="8000" step="500">
                </div>
            </div>
            <div class="config-row">
            <div class="config-row">
                <div class="config-group" style="flex: 1 1 100%;">
                    <label>System Prompt</label>
                    <textarea id="systemPrompt" placeholder="You are a helpful AI assistant...">You are a helpful AI assistant having a conversation. Keep responses very brief (1-2 sentences). IMPORTANT: Always start your response with the word "Echo" followed by a comma, then your actual response. Example: "Echo, that's interesting!" or "Echo, I think..."</textarea>
                </div>
            </div>
        </div>

        <div class="status">
            <div class="status-indicator" id="statusIndicator"></div>
            <div class="status-text" id="statusText">Ready to start</div>
        </div>

        <div class="controls">
            <button class="btn-primary" id="startBtn">Start Listening</button>
            <button class="btn-secondary" id="stopBtn" disabled>Stop</button>
        </div>

        <div class="transcript-area" id="transcriptArea">
            <div style="text-align: center; color: #999; padding: 20px;">
                Conversation will appear here...
            </div>
        </div>

        <div class="info-text">
            <strong>ðŸ”§ API Info:</strong><br>
            Using Pollinations.AI API with referrer: www.ai-ministries.com
        </div>

        <div class="help-text">
            <strong>ðŸ’¡ How to use:</strong><br>
            <strong>Continuous Mode:</strong> AI responds to any speech it hears - great for natural conversation flow!<br>
            <strong>Wake Word Mode:</strong> Say the wake word (e.g., "Assistant, tell me a joke") to trigger AI response<br>
            <br>
            The AI will always start responses with "Echo" to trigger your Echo device and keep the conversation going.
        </div>
    </div>

    <script>
        // Configuration
        const API_BASE = 'https://text.pollinations.ai/openai';
        const REFERRER = 'www.ai-ministries.com';
        
        let recognition;
        let synthesis = window.speechSynthesis;
        let isListening = false;
        let silenceTimer;
        let currentTranscript = '';
        let isProcessing = false;
        let conversationHistory = [];
        let lastProcessedText = '';

        // DOM Elements
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusIndicator = document.getElementById('statusIndicator');
        const statusText = document.getElementById('statusText');
        const transcriptArea = document.getElementById('transcriptArea');
        const aiWakeWordInput = document.getElementById('aiWakeWord');
        const silenceThresholdInput = document.getElementById('silenceThreshold');
        const postSpeechPauseInput = document.getElementById('postSpeechPause');
        const aiModelSelect = document.getElementById('aiModel');
        const systemPromptInput = document.getElementById('systemPrompt');
        const responseModeSelect = document.getElementById('responseMode');
        const wakeWordGroup = document.getElementById('wakeWordGroup');

        // Toggle wake word visibility based on mode
        responseModeSelect.addEventListener('change', () => {
            if (responseModeSelect.value === 'continuous') {
                wakeWordGroup.style.display = 'none';
            } else {
                wakeWordGroup.style.display = 'block';
            }
        });

        // Initialize visibility
        if (responseModeSelect.value === 'continuous') {
            wakeWordGroup.style.display = 'none';
        }

        // Initialize Speech Recognition
        function initRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            
            if (!SpeechRecognition) {
                alert('Speech recognition not supported in this browser. Please use Chrome or Edge.');
                return null;
            }

            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onresult = (event) => {
                // Don't process if browser is actively speaking or we're processing
                if (synthesis.speaking || isProcessing) return;

                let interimTranscript = '';
                let finalTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' ';
                    } else {
                        interimTranscript += transcript;
                    }
                }

                if (finalTranscript) {
                    currentTranscript += finalTranscript;
                    resetSilenceTimer();
                }
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                if (event.error === 'no-speech' || event.error === 'aborted') {
                    if (isListening && !synthesis.speaking) {
                        setTimeout(() => {
                            try {
                                recognition.start();
                            } catch (e) {
                                console.log('Recognition already started');
                            }
                        }, 100);
                    }
                }
            };

            recognition.onend = () => {
                if (isListening && !synthesis.speaking && !isProcessing) {
                    setTimeout(() => {
                        try {
                            recognition.start();
                        } catch (e) {
                            console.log('Recognition already started');
                        }
                    }, 100);
                }
            };

            return recognition;
        }

        // Silence Detection
        function resetSilenceTimer() {
            clearTimeout(silenceTimer);
            const threshold = parseInt(silenceThresholdInput.value);
            
            silenceTimer = setTimeout(() => {
                if (currentTranscript.trim() && !isProcessing && !synthesis.speaking) {
                    processTranscript(currentTranscript.trim());
                    currentTranscript = '';
                }
            }, threshold);
        }

        // Check if text is similar to last processed (avoid duplicates)
        function isSimilarToLast(text) {
            if (!lastProcessedText) return false;
            
            const normalizedNew = text.toLowerCase().trim();
            const normalizedLast = lastProcessedText.toLowerCase().trim();
            
            // Exact match
            if (normalizedNew === normalizedLast) return true;
            
            // Check if one contains the other (partial duplicates)
            if (normalizedNew.includes(normalizedLast) || normalizedLast.includes(normalizedNew)) {
                return true;
            }
            
            return false;
        }

        // Process captured speech
        async function processTranscript(text) {
            if (isProcessing || synthesis.speaking) return;

            // Ignore if too similar to last processed text
            if (isSimilarToLast(text)) {
                console.log('Ignoring duplicate/similar text:', text);
                return;
            }

            lastProcessedText = text;

            const responseMode = responseModeSelect.value;
            const lowerText = text.toLowerCase();

            addMessage('user', text);

            // Determine if we should respond
            let shouldRespond = false;
            let message = text;

            if (responseMode === 'continuous') {
                // Respond to everything
                shouldRespond = true;
            } else if (responseMode === 'wakeword') {
                const aiWakeWord = aiWakeWordInput.value.toLowerCase();
                // Only respond if wake word is present
                if (lowerText.includes(aiWakeWord)) {
                    shouldRespond = true;
                    // Extract the message after wake word
                    const wakeIndex = lowerText.indexOf(aiWakeWord);
                    message = text.substring(wakeIndex + aiWakeWord.length).trim();
                }
            }

            if (shouldRespond && message.trim()) {
                isProcessing = true;
                updateStatus('processing', 'Processing your request...');

                const response = await getAIResponse(message);
                
                if (response) {
                    addMessage('ai', response);
                    await speakText(response);
                    
                    // Wait a moment after speaking finishes
                    await new Promise(resolve => setTimeout(resolve, 1000));
                    updateStatus('listening', 'Listening...');
                }

                isProcessing = false;
            }
        }

        // Pause listening for a period after speaking
        async function pauseListening() {
            isPaused = true;
            const pauseDuration = parseInt(postSpeechPauseInput.value);
            updateStatus('paused', `Pausing for ${pauseDuration/1000}s...`);
            
            await new Promise(resolve => setTimeout(resolve, pauseDuration));
            
            isPaused = false;
            if (isListening) {
                updateStatus('listening', 'Listening...');
            }
        }

        // Get AI Response using Pollinations API
        async function getAIResponse(message) {
            const model = aiModelSelect.value;
            const systemPrompt = systemPromptInput.value.trim();

            // Build messages array
            const messages = [];
            
            if (systemPrompt) {
                messages.push({
                    role: 'system',
                    content: systemPrompt
                });
            }

            // Add conversation history (last 4 messages)
            const recentHistory = conversationHistory.slice(-4);
            messages.push(...recentHistory);

            // Add current message
            messages.push({
                role: 'user',
                content: message
            });

            try {
                const requestBody = {
                    model: model,
                    messages: messages,
                    stream: false
                };

                console.log('API Request:', JSON.stringify(requestBody, null, 2));

                const response = await fetch(`${API_BASE}?referrer=${encodeURIComponent(REFERRER)}`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(requestBody)
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    console.error('API Response:', errorText);
                    throw new Error(`API Error: ${response.status} - ${errorText}`);
                }

                const data = await response.json();
                console.log('API Response:', data);
                
                const aiResponse = data.choices[0].message.content;

                // Update conversation history
                conversationHistory.push({
                    role: 'user',
                    content: message
                });
                conversationHistory.push({
                    role: 'assistant',
                    content: aiResponse
                });

                return aiResponse;

            } catch (error) {
                console.error('API Error:', error);
                addMessage('system', `Error: ${error.message}`);
                
                // Fallback response
                return `Interesting point about ${message}. Echo, what do you think?`;
            }
        }

        // Text to Speech
        function speakText(text) {
            return new Promise((resolve) => {
                updateStatus('speaking', 'Speaking...');
                
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 0.9;
                utterance.pitch = 1.0;
                utterance.volume = 1.0;

                utterance.onend = () => {
                    resolve();
                };

                utterance.onerror = () => {
                    resolve();
                };

                synthesis.speak(utterance);
            });
        }

        // UI Updates
        function updateStatus(state, text) {
            statusIndicator.className = 'status-indicator ' + state;
            statusText.textContent = text;
        }

        function addMessage(type, text) {
            const messageDiv = document.createElement('div');
            messageDiv.className = 'message ' + type;
            
            let label = 'System';
            if (type === 'user') label = 'You';
            else if (type === 'ai') label = 'AI';
            else if (type === 'echo') label = 'Echo';
            
            messageDiv.innerHTML = `<strong>${label}:</strong>${text}`;
            
            if (transcriptArea.children[0]?.style.textAlign === 'center') {
                transcriptArea.innerHTML = '';
            }
            
            transcriptArea.appendChild(messageDiv);
            transcriptArea.scrollTop = transcriptArea.scrollHeight;
        }

        // Event Listeners
        startBtn.addEventListener('click', () => {
            if (!recognition) {
                recognition = initRecognition();
            }
            
            if (recognition) {
                isListening = true;
                conversationHistory = [];
                lastProcessedText = '';
                
                try {
                    recognition.start();
                } catch (e) {
                    console.log('Recognition start error:', e);
                }
                
                updateStatus('listening', 'Listening...');
                startBtn.disabled = true;
                stopBtn.disabled = false;
                transcriptArea.innerHTML = '';
            }
        });

        stopBtn.addEventListener('click', () => {
            isListening = false;
            
            if (recognition) {
                try {
                    recognition.stop();
                } catch (e) {
                    console.log('Recognition stop error:', e);
                }
            }
            if (synthesis.speaking) {
                synthesis.cancel();
            }
            clearTimeout(silenceTimer);
            updateStatus('', 'Stopped');
            startBtn.disabled = false;
            stopBtn.disabled = true;
            isProcessing = false;
        });

        // Initialize
        if ('speechSynthesis' in window && (window.SpeechRecognition || window.webkitSpeechRecognition)) {
            console.log('Speech APIs ready');
        } else {
            alert('Your browser does not support the required speech APIs.');
        }
    </script>
</body>
</html>